2025-01-09 23:21:36,795 INFO    MainThread:118095 [wandb_setup.py:_flush():68] Current SDK version is 0.19.1
2025-01-09 23:21:36,795 INFO    MainThread:118095 [wandb_setup.py:_flush():68] Configure stats pid to 118095
2025-01-09 23:21:36,795 INFO    MainThread:118095 [wandb_setup.py:_flush():68] Loading settings from /gpfsnyu/home/ny2208/.config/wandb/settings
2025-01-09 23:21:36,795 INFO    MainThread:118095 [wandb_setup.py:_flush():68] Loading settings from /gpfsnyu/scratch/ny2208/jch/graphprompter/graphprompter_recompose/wandb/settings
2025-01-09 23:21:36,795 INFO    MainThread:118095 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-01-09 23:21:36,795 INFO    MainThread:118095 [wandb_init.py:_log_setup():528] Logging user logs to /gpfsnyu/scratch/ny2208/jch/graphprompter/graphprompter_recompose/wandb/offline-run-20250109_232136-f6g563hf/logs/debug.log
2025-01-09 23:21:36,795 INFO    MainThread:118095 [wandb_init.py:_log_setup():529] Logging internal logs to /gpfsnyu/scratch/ny2208/jch/graphprompter/graphprompter_recompose/wandb/offline-run-20250109_232136-f6g563hf/logs/debug-internal.log
2025-01-09 23:21:36,795 INFO    MainThread:118095 [wandb_init.py:init():644] calling init triggers
2025-01-09 23:21:36,796 INFO    MainThread:118095 [wandb_init.py:init():650] wandb.init called with sweep_config: {}
config: {'model_name': 'graph_llm', 'project': 'graph_prompt_tuning', 'seed': 0, 'dataset': 'cora_semi', 'lr': 1e-05, 'wd': 0.05, 'patience': 2.0, 'min_lr': 5e-06, 'resume': '', 'batch_size': 12, 'grad_steps': 2, 'num_epochs': 15, 'warmup_epochs': 1, 'eval_batch_size': 8, 'llm_model_name': '7b', 'llm_model_path': '/gpfsnyu/scratch/ny2208/jch/graphprompter/graphprompter_recompose/Llama-2-7b-hf', 'llm_frozen': 'True', 'llm_num_virtual_tokens': 10, 'output_dir': 'output', 'max_txt_len': 512, 'max_new_tokens': 32, 'adapter_len': 10, 'adapter_layer': 30, 'log_dir': 'logs/', 'device': 'cuda:0', 'world_size': 1, 'local_rank': -1, 'gpu': '0', 'rank': -1, 'dist_on_itp': True, 'dist_url': 'env://', 'num_workers': 8, 'gnn_model_name': 'gat', 'gnn_num_layers': 4, 'gnn_in_dim': 1024, 'gnn_hidden_dim': 1024, 'gnn_out_dim': 1024, 'gnn_num_heads': 4, 'gnn_dropout': 0.0}
2025-01-09 23:21:36,796 INFO    MainThread:118095 [wandb_init.py:init():680] starting backend
2025-01-09 23:21:36,796 INFO    MainThread:118095 [wandb_init.py:init():684] sending inform_init request
2025-01-09 23:21:36,823 INFO    MainThread:118095 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-01-09 23:21:36,827 INFO    MainThread:118095 [wandb_init.py:init():697] backend started and connected
2025-01-09 23:21:36,831 INFO    MainThread:118095 [wandb_init.py:init():790] updated telemetry
2025-01-09 23:21:36,876 INFO    MainThread:118095 [wandb_init.py:init():822] communicating run to backend with 90.0 second timeout
2025-01-09 23:21:36,963 INFO    MainThread:118095 [wandb_init.py:init():874] starting run threads in backend
2025-01-09 23:21:37,084 INFO    MainThread:118095 [wandb_run.py:_console_start():2374] atexit reg
2025-01-09 23:21:37,085 INFO    MainThread:118095 [wandb_run.py:_redirect():2224] redirect: wrap_raw
2025-01-09 23:21:37,085 INFO    MainThread:118095 [wandb_run.py:_redirect():2289] Wrapping output streams.
2025-01-09 23:21:37,085 INFO    MainThread:118095 [wandb_run.py:_redirect():2314] Redirects installed.
2025-01-09 23:21:37,283 INFO    MainThread:118095 [wandb_init.py:init():916] run started, returning control to user process
2025-01-09 23:21:37,326 WARNING MsgRouterThr:118095 [router.py:message_loop():75] message_loop has been closed
